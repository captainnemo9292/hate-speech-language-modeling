{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network based Hate Speech Language Model for Korean Hate Speech Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Scraping Raw Hate Speech Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "list_size = 10000\n",
    "url = 'https://www.ilbe.com/list/ilbe?listSize={}&sub=best&listStyle=list'.format(list_size)\n",
    "driver = webdriver.Chrome(executable_path = 'D:\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "url_list = []\n",
    "post_list = driver.find_elements_by_xpath('//ul[contains(@class, \\'board-body\\')]//li[not(@id) and not(@class)]//span[contains(@class, \\'title\\')]//a[contains(@class, \\'subject\\')]')\n",
    "for post_num in range(len(post_list)):\n",
    "    print(post_num, post_list[post_num].get_attribute('href'))\n",
    "    url_list.append(post_list[post_num].get_attribute('href'))\n",
    "    pd.Series(url_list).to_frame(name='url').to_csv('url_list_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "hate_speech_list = pd.read_csv('hate_speech_raw_data.csv')['hate_speech'].tolist()\n",
    "#hate_speech_list = []\n",
    "url_list = pd.read_csv('url_list_v2.csv')['url'].tolist()\n",
    "\n",
    "i = 1185\n",
    "driver = webdriver.Chrome(executable_path = 'D:\\chromedriver_win32\\chromedriver.exe')\n",
    "for url_num in range(i, len(url_list)):\n",
    "    driver.get(url_list[url_num])\n",
    "    comment_list = driver.find_elements_by_xpath('//span[contains(@class, \\'comment-box\\')]')\n",
    "    for comment in comment_list:\n",
    "        hate_speech_list.append(comment.text)\n",
    "        print(url_num, comment.text) \n",
    "    pd.Series(hate_speech_list).to_frame(name='hate_speech').drop_duplicates().reset_index(drop=True).to_csv('hate_speech_raw_data.csv', index=False)           \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129446</th>\n",
       "      <td>전라씨발 전라컹새끼들ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129447</th>\n",
       "      <td>ㅈㄹㄷ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129448</th>\n",
       "      <td>5월 영상을 지금 들먹이노 ㅋㅋㅋㅋ ㅇㅂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129449</th>\n",
       "      <td>경찰대 나와서 엘리트출신도 아니도 그냥 경찰딱지달고 나부랭이들은 저런 결정권 주면 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129450</th>\n",
       "      <td>옜날꺼 ㅁㅈㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hate_speech\n",
       "129446                                     전라씨발 전라컹새끼들ㅋㅋㅋ\n",
       "129447                                                ㅈㄹㄷ\n",
       "129448                             5월 영상을 지금 들먹이노 ㅋㅋㅋㅋ ㅇㅂ\n",
       "129449  경찰대 나와서 엘리트출신도 아니도 그냥 경찰딱지달고 나부랭이들은 저런 결정권 주면 ...\n",
       "129450                                            옜날꺼 ㅁㅈㅎ"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('hate_speech_raw_data.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Text Preprocessing with KoNLPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt  \n",
    "import pandas as pd \n",
    "\n",
    "okt =  Okt()\n",
    "data = pd.read_csv('hate_speech_raw_data.csv')\n",
    "\n",
    "for i in range(len(data['hate_speech'])):\n",
    "    \n",
    "    sentence = ''\n",
    "    try:\n",
    "        for word in okt.nouns(data['hate_speech'][i]):\n",
    "            sentence = sentence + ' ' + word\n",
    "    except:\n",
    "        pass\n",
    "    data['hate_speech'][i] = sentence\n",
    "    print(i ,data['hate_speech'][i])\n",
    "    data.to_csv('hate_speech_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129446</th>\n",
       "      <td>전라  전라 컹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129447</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129448</th>\n",
       "      <td>영상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129449</th>\n",
       "      <td>경찰대 엘리트 출신  경찰 달 나부랭이 저런 결정 줫  뭔가 결정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129450</th>\n",
       "      <td>옜날꺼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  hate_speech\n",
       "129446                              전라  전라 컹 \n",
       "129447                                       \n",
       "129448                                    영상 \n",
       "129449   경찰대 엘리트 출신  경찰 달 나부랭이 저런 결정 줫  뭔가 결정\n",
       "129450                                    옜날꺼"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text = pd.read_csv('hate_speech_data.csv').fillna(' ').replace(to_replace=['존나', '진짜', '사람', '나라', '생각', '이건', '씨발', '시발', '일베', '익명', '병신', '재앙', '문재인', '게이', '이기', '댓글', '정보', '새끼', '지랄', '개새끼', '그냥', '보고', '아주', '얼굴', '한국', '우리', '지금', '대통령', '홍어', '분탕'], value=\"\",regex=True)\n",
    "text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129451, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features= 10000) # 상위 10,000개의 단어를 보존 \n",
    "X = vectorizer.fit_transform(text['hate_speech'])\n",
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=5,random_state=777,max_iter=1).fit(X)\n",
    "nmf_top = nmf_model.fit_transform(X)\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('전라도', 4.96), ('출신', 0.09), ('경상도', 0.08), ('민주당', 0.07), ('고향', 0.07), ('때문', 0.07), ('대한민국', 0.06), ('서울', 0.05), ('지역', 0.05), ('광주', 0.05), ('세상', 0.04), ('지지율', 0.04), ('인간', 0.04), ('팩트', 0.04), ('특징', 0.04), ('사투리', 0.03), ('좌빨', 0.03), ('문제', 0.03), ('어디', 0.03), ('하나', 0.03), ('부모', 0.03), ('사회', 0.03), ('김대중', 0.03), ('부산', 0.03), ('혐오', 0.03), ('저런', 0.03), ('지지', 0.03), ('역시', 0.03), ('쓰레기', 0.03), ('북한', 0.03), ('독립', 0.03), ('사절', 0.03), ('정말', 0.03), ('이제', 0.03), ('동네', 0.02), ('통수', 0.02), ('거지', 0.02), ('버러지', 0.02), ('고향이', 0.02), ('카르텔', 0.02), ('폭동', 0.02), ('대구', 0.02), ('과학', 0.02), ('자기', 0.02), ('기업', 0.02), ('유전자', 0.02), ('자체', 0.02), ('조선족', 0.02), ('정도', 0.02), ('원래', 0.02)]\n",
      "Topic 2: [('좌파', 3.04), ('우파', 0.99), ('소리', 0.97), ('국민', 0.83), ('미국', 0.79), ('개돼지', 0.77), ('북한', 0.77), ('정권', 0.7), ('박근혜', 0.68), ('하나', 0.64), ('수준', 0.6), ('좌빨', 0.57), ('보수', 0.57), ('선동', 0.56), ('정도', 0.56), ('때문', 0.55), ('문제', 0.55), ('대가리', 0.53), ('저런', 0.51), ('정치', 0.5), ('좌좀', 0.5), ('탄핵', 0.48), ('일본', 0.45), ('대한민국', 0.44), ('노무현', 0.44), ('이제', 0.43), ('자기', 0.39), ('무슨', 0.38), ('정부', 0.37), ('국가', 0.36), ('사실', 0.35), ('짱깨', 0.35), ('역시', 0.34), ('언론', 0.34), ('팩트', 0.33), ('쓰레기', 0.32), ('민주당', 0.32), ('이유', 0.31), ('인간', 0.31), ('누가', 0.29), ('거지', 0.29), ('어디', 0.27), ('정신', 0.26), ('보지', 0.25), ('방송', 0.25), ('자체', 0.24), ('애국', 0.24), ('자유', 0.23), ('조선', 0.23), ('정말', 0.23)]\n",
      "Topic 3: [('중국', 3.26), ('북한', 0.79), ('미국', 0.68), ('짱깨', 0.24), ('일본', 0.19), ('간첩', 0.19), ('짱개', 0.1), ('공산당', 0.06), ('대만', 0.06), ('조선족', 0.05), ('러시아', 0.05), ('중국인', 0.04), ('시진핑', 0.04), ('입국', 0.04), ('전쟁', 0.04), ('폐렴', 0.04), ('속국', 0.04), ('매국노', 0.03), ('우한', 0.03), ('세계', 0.03), ('먼저', 0.03), ('금지', 0.03), ('마스크', 0.03), ('여행', 0.03), ('홍콩', 0.03), ('베트남', 0.03), ('전세계', 0.03), ('자본', 0.03), ('한반도', 0.03), ('붕괴', 0.03), ('남한', 0.02), ('미세먼지', 0.02), ('공장', 0.02), ('화교', 0.02), ('기술', 0.02), ('수출', 0.02), ('사드', 0.02), ('경제', 0.02), ('주적', 0.02), ('바퀴벌레', 0.02), ('트럼프', 0.02), ('식민지', 0.02), ('식인종', 0.02), ('인도', 0.02), ('투자', 0.02), ('국내', 0.02), ('침략', 0.02), ('달러', 0.02), ('필리핀', 0.02), ('스파이', 0.02)]\n",
      "Topic 4: [('여자', 3.78), ('남자', 1.03), ('보지', 0.3), ('결혼', 0.26), ('저런', 0.12), ('정도', 0.11), ('김치', 0.09), ('일본', 0.08), ('섹스', 0.08), ('어디', 0.08), ('역시', 0.08), ('페미', 0.07), ('누구', 0.06), ('자기', 0.06), ('인생', 0.06), ('사진', 0.05), ('문제', 0.05), ('한번', 0.05), ('정말', 0.05), ('이해', 0.04), ('외모', 0.04), ('여자도', 0.04), ('남편', 0.04), ('군대', 0.04), ('이유', 0.04), ('가슴', 0.03), ('엄마', 0.03), ('때문', 0.03), ('보통', 0.03), ('여성', 0.03), ('스시', 0.03), ('라면', 0.03), ('먼저', 0.03), ('사랑', 0.03), ('능력', 0.03), ('이상', 0.03), ('강간', 0.03), ('제일', 0.03), ('인기', 0.03), ('투표', 0.03), ('부모', 0.03), ('사실', 0.03), ('이혼', 0.03), ('바람', 0.03), ('무슨', 0.03), ('대부분', 0.03), ('주변', 0.03), ('직업', 0.03), ('그게', 0.03), ('얘기', 0.03)]\n",
      "Topic 5: [('빨갱이', 3.9), ('개돼지', 0.19), ('보지', 0.17), ('종북', 0.06), ('간첩', 0.06), ('토착', 0.05), ('공산당', 0.03), ('주사파', 0.03), ('매국노', 0.03), ('대한민국', 0.03), ('진성', 0.03), ('선동', 0.03), ('문죄인', 0.02), ('개좆', 0.02), ('친일파', 0.02), ('진보', 0.02), ('자유', 0.02), ('이제', 0.02), ('다음', 0.02), ('단체', 0.02), ('애비', 0.02), ('하나', 0.02), ('색기', 0.02), ('좌좀', 0.02), ('임종석', 0.02), ('장악', 0.02), ('청와대', 0.02), ('정권', 0.02), ('친일', 0.02), ('문씨', 0.02), ('공산주의', 0.02), ('소굴', 0.02), ('면상', 0.02), ('비서실', 0.02), ('종특', 0.02), ('국가', 0.02), ('척결', 0.02), ('중도', 0.02), ('마리', 0.02), ('북괴', 0.02), ('전향', 0.02), ('자생', 0.02), ('경남', 0.02), ('짓거리', 0.02), ('멸종', 0.02), ('세상', 0.01), ('점점', 0.01), ('로남불', 0.01), ('하여튼', 0.01), ('악마', 0.01)]\n"
     ]
    }
   ],
   "source": [
    "def get_topics(components, feature_names, n=50):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(nmf_model.components_,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23589</th>\n",
       "      <td>신후게이야 ㅠㅠ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23590</th>\n",
       "      <td>최순실 300조 안민돌새끼는 진짜 사기죄로 처넣어야함\\n\\n일본의 무력에 굴복해서 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23591</th>\n",
       "      <td>경상도일 확률 1026%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23592</th>\n",
       "      <td>개쌍도가주도하는질서전라도가기생충처럼나라를살</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23593</th>\n",
       "      <td>아무래도 우파로 간 김미균을 시기하는\\n좌파들의 공작이 시작 된듯 하다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장  혐오 여부\n",
       "23589                                           신후게이야 ㅠㅠ      0\n",
       "23590  최순실 300조 안민돌새끼는 진짜 사기죄로 처넣어야함\\n\\n일본의 무력에 굴복해서 ...      0\n",
       "23591                                      경상도일 확률 1026%      3\n",
       "23592                            개쌍도가주도하는질서전라도가기생충처럼나라를살      1\n",
       "23593            아무래도 우파로 간 김미균을 시기하는\\n좌파들의 공작이 시작 된듯 하다      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text_df = pd.read_csv('hate_speech_topic_dataset.csv', index_col=0)\n",
    "text_df['문장'] = text_df['문장'].astype('str').replace({'0': \"특정 지역에 대한 차별적 발언\", '1': \"정치적 성향이 다른 사람들에 대한 혐오 및 왜곡\", '2':  \"다른 나라에 대한 차별적 발언\", '3': \"여성 및 성소수자에 대한 혐오 및 왜곡\"})\n",
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "text = pd.read_csv('hate_speech_raw_data.csv', index_col=0)\n",
    "text['topic'] = np.nan\n",
    "\n",
    "for i in range(len(nmf_top)):\n",
    "    text['topic'][i] = np.argmax(nmf_top[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[text['topic']!=4.0].reset_index().to_csv('hate_speech_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Training Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    96009\n",
       "0.0    19805\n",
       "2.0     5800\n",
       "3.0     5795\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate_text = pd.read_csv('hate_speech_data_cleaned.csv')\n",
    "hate_text['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3793074</td>\n",
       "      <td>귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3025658</td>\n",
       "      <td>이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7698359</td>\n",
       "      <td>값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7068653</td>\n",
       "      <td>짱</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3206900</td>\n",
       "      <td>파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      document  label\n",
       "99995  3793074  귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!      1\n",
       "99996  3025658           이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!      1\n",
       "99997  7698359                값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ      1\n",
       "99998  7068653                                             짱      1\n",
       "99999  3206900                  파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_text = pd.read_csv('ratings.txt', sep='\\t', quoting=3)\n",
    "random_text = random_text[random_text['label'] == 1].reset_index(drop=True)\n",
    "random_text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate_text = pd.read_csv('hate_speech_data_cleaned.csv')\n",
    "random_text = random_text[random_text['label'] == 1].reset_index(drop=True)\n",
    "\n",
    "dataset_dir = 'hate_speech_binary_dataset.csv'\n",
    "dataframe = pd.DataFrame(columns=['문장', '혐오 여부'])\n",
    "dataframe.to_csv(dataset_dir, index=False)\n",
    "dataframe = pd.read_csv(dataset_dir)\n",
    "\n",
    "count = 0 \n",
    "\n",
    "for q in hate_text['hate_speech']:\n",
    "    data = pd.DataFrame({'문장': q, '혐오 여부': 1}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n",
    "    \n",
    "for t in random_text['document'][:len(hate_text['hate_speech'])]:\n",
    "    data = pd.DataFrame({'문장': t, '혐오 여부': 0}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6000\n",
       "0    5999\n",
       "2    5800\n",
       "3    5795\n",
       "Name: 혐오 여부, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "dataset_dir = 'hate_speech_topic_dataset.csv'\n",
    "df = shuffle(pd.read_csv('hate_speech_topic_dataset.csv', index_col=0)).reset_index(drop=True)\n",
    "df.to_csv(dataset_dir)\n",
    "df['혐오 여부'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>그러면 강아지랑 그것도 하셨네</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>목줄안하고있는 개새끼들 죽여도 무죄아님?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>목줄 안해요 내가 안해요 내가 안하겠다는건데 누가 시킨다는거요</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>왼쪽이 닥터드레냐?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>@앙마의속삭임 Dr.Dog</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              hate_speech  topic\n",
       "89995                    그러면 강아지랑 그것도 하셨네    1.0\n",
       "89996              목줄안하고있는 개새끼들 죽여도 무죄아님?    1.0\n",
       "89997  목줄 안해요 내가 안해요 내가 안하겠다는건데 누가 시킨다는거요    1.0\n",
       "89998                          왼쪽이 닥터드레냐?    1.0\n",
       "89999                      @앙마의속삭임 Dr.Dog    0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate_text = pd.read_csv('hate_speech_data_cleaned.csv', index_col=0)[:90000]\n",
    "hate_text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>그러면 강아지랑 그것도 하셨네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>목줄안하고있는 개새끼들 죽여도 무죄아님?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>목줄 안해요 내가 안해요 내가 안하겠다는건데 누가 시킨다는거요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>왼쪽이 닥터드레냐?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>@앙마의속삭임 Dr.Dog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       문장  혐오 여부\n",
       "89995                    그러면 강아지랑 그것도 하셨네      0\n",
       "89996              목줄안하고있는 개새끼들 죽여도 무죄아님?      0\n",
       "89997  목줄 안해요 내가 안해요 내가 안하겠다는건데 누가 시킨다는거요      0\n",
       "89998                          왼쪽이 닥터드레냐?      0\n",
       "89999                      @앙마의속삭임 Dr.Dog      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'문장':hate_text['hate_speech'].tolist(), '혐오 여부':[0] * len(hate_text['hate_speech'].tolist())}\n",
    "df_0 = pd.DataFrame(data) \n",
    "df_0.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3793074</td>\n",
       "      <td>귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3025658</td>\n",
       "      <td>이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7698359</td>\n",
       "      <td>값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7068653</td>\n",
       "      <td>짱</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3206900</td>\n",
       "      <td>파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      document  label\n",
       "99995  3793074  귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!      1\n",
       "99996  3025658           이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!      1\n",
       "99997  7698359                값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ      1\n",
       "99998  7068653                                             짱      1\n",
       "99999  3206900                  파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_text = pd.read_csv('ratings.txt', sep='\\t', quoting=3)\n",
    "random_text = random_text[random_text['label'] == 1].reset_index(drop=True)\n",
    "random_text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>짱</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 문장  혐오 여부\n",
       "99995  귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!      1\n",
       "99996           이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!      1\n",
       "99997                값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ      1\n",
       "99998                                             짱      1\n",
       "99999                  파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'문장':random_text['document'].tolist(), '혐오 여부':[1] * len(random_text['document'].tolist())}\n",
    "df_1 = pd.DataFrame(data) \n",
    "df_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189995</th>\n",
       "      <td>귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189996</th>\n",
       "      <td>이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189997</th>\n",
       "      <td>값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189998</th>\n",
       "      <td>짱</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189999</th>\n",
       "      <td>파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  문장  혐오 여부\n",
       "189995  귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!      1\n",
       "189996           이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!      1\n",
       "189997                값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ      1\n",
       "189998                                             짱      1\n",
       "189999                  파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.concat([df_0, df_1])\n",
    "df.reset_index(drop=True).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189995</th>\n",
       "      <td>원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189996</th>\n",
       "      <td>케석대 어깨 올라간거봐라 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189997</th>\n",
       "      <td>@김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189998</th>\n",
       "      <td>로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189999</th>\n",
       "      <td>@익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       문장  혐오 여부\n",
       "189995  원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...      1\n",
       "189996                                   케석대 어깨 올라간거봐라 ㅋㅋ      0\n",
       "189997  @김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...      0\n",
       "189998           로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음      1\n",
       "189999                         @익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "dataframe = shuffle(df).reset_index(drop=True)\n",
    "dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100000\n",
       "0     90000\n",
       "Name: 혐오 여부, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['혐오 여부'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('hate_speech_binary_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100000\n",
       "0     90000\n",
       "Name: 혐오 여부, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "df = shuffle(pd.read_csv('hate_speech_binary_dataset.csv', index_col=0)).reset_index(drop=True)\n",
    "df.to_csv(dataset_dir)\n",
    "df['혐오 여부'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate_text = pd.read_csv('hate_speech_data_cleaned.csv')\n",
    "hate_text_0 = hate_text[hate_text['topic'] == 0].reset_index(drop=True)\n",
    "hate_text_1 = hate_text[hate_text['topic'] == 1].reset_index(drop=True)\n",
    "hate_text_2 = hate_text[hate_text['topic'] == 2].reset_index(drop=True)\n",
    "hate_text_3 = hate_text[hate_text['topic'] == 3].reset_index(drop=True)\n",
    "random_text = random_text[random_text['label'] == 1].reset_index(drop=True)\n",
    "\n",
    "dataset_dir = 'hate_speech_dataset.csv'\n",
    "dataframe = pd.DataFrame(columns=['문장', '혐오 여부'])\n",
    "dataframe.to_csv(dataset_dir, index=False)\n",
    "dataframe = pd.read_csv(dataset_dir)\n",
    "\n",
    "count = 0 \n",
    "\n",
    "for q in hate_text_0['hate_speech'][:6000]:\n",
    "    data = pd.DataFrame({'문장': q, '혐오 여부': 0}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n",
    "    \n",
    "for w in hate_text_1['hate_speech'][:6000]:\n",
    "    data = pd.DataFrame({'문장': w, '혐오 여부':1}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n",
    "\n",
    "for e in hate_text_2['hate_speech']:#[:1900]:\n",
    "    data = pd.DataFrame({'문장': e, '혐오 여부': 2}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n",
    "    \n",
    "for r in hate_text_3['hate_speech']:#[:1900]:\n",
    "    data = pd.DataFrame({'문장': r, '혐오 여부': 3}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n",
    "\n",
    "for t in random_text['document'][:8000]:\n",
    "    data = pd.DataFrame({'문장': t, '혐오 여부': 4}, index=[0])\n",
    "    dataframe = dataframe.append(data, ignore_index=True)\n",
    "    dataframe.drop_duplicates().dropna().reset_index(drop=True).to_csv(dataset_dir)\n",
    "    count = count+1\n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31502</th>\n",
       "      <td>일게이 퀄리티 살아잇노</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31503</th>\n",
       "      <td>제가 서부 영화를 좋아하는 데, 짱이네요.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31504</th>\n",
       "      <td>최고의 영화!! 말이 필요없습니다.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31505</th>\n",
       "      <td>관심주지마라</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31506</th>\n",
       "      <td>아무도 부정할 수 없는 우리네 모습</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            문장  혐오 여부\n",
       "31502             일게이 퀄리티 살아잇노      1\n",
       "31503  제가 서부 영화를 좋아하는 데, 짱이네요.      4\n",
       "31504      최고의 영화!! 말이 필요없습니다.      4\n",
       "31505                   관심주지마라      1\n",
       "31506      아무도 부정할 수 없는 우리네 모습      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "dataset_dir = 'hate_speech_dataset.csv'\n",
    "df = shuffle(pd.read_csv('hate_speech_dataset.csv', index_col=0)).reset_index(drop=True)\n",
    "df.to_csv(dataset_dir)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3793074</td>\n",
       "      <td>귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3025658</td>\n",
       "      <td>이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7698359</td>\n",
       "      <td>값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7068653</td>\n",
       "      <td>짱</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3206900</td>\n",
       "      <td>파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      document  label\n",
       "99995  3793074  귀신보다 사람이 얼마나 무서운가를 보여주는.. 메시지까지 담고있는 드라마~최고!      1\n",
       "99996  3025658           이라크 및 아랍과의 전쟁을 그린 모든 영화 중에서 가장 최고!!      1\n",
       "99997  7698359                값으로 환산할 수 없을 만큼 귀엽고 황홀한 캐릭터 ㅠㅠ      1\n",
       "99998  7068653                                             짱      1\n",
       "99999  3206900                  파괴지왕에서 장학우 콘서트 티켓을 얻기위한... ㅋ      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_text = pd.read_csv('ratings.txt', sep='\\t', quoting=3)\n",
    "random_text = random_text[random_text['label'] == 1].reset_index(drop=True)\n",
    "random_text = random_text[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('hate_speech_topic_dataset.csv', index_col=0)\n",
    "data[data['혐오 여부']==0].reset_index(drop=True).to_csv('hate_speech_topic_region.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "class TextRNN(object):\n",
    "    def __init__(self, maxlen, max_features, embedding_dims,\n",
    "                 class_num=2,\n",
    "                 last_activation='softmax'):\n",
    "        self.maxlen = maxlen\n",
    "        self.max_features = max_features\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.class_num = class_num\n",
    "        self.last_activation = last_activation\n",
    "\n",
    "    def get_model(self):\n",
    "        input = Input((self.maxlen,))\n",
    "\n",
    "        embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)(input)\n",
    "        x = LSTM(128)(embedding)  # LSTM or GRU\n",
    "\n",
    "        output = Dense(self.class_num, activation=self.last_activation)(x)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 128, 50)           250000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 341,906\n",
      "Trainable params: 341,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_features = 5000\n",
    "maxlen = 128\n",
    "batch_size = 64\n",
    "embedding_dims = 50\n",
    "epochs = 100\n",
    "\n",
    "data = pd.read_csv('hate_speech_binary_dataset.csv').dropna().reset_index(drop=True)\n",
    "data[\"문장\"] = data[\"문장\"].astype('string')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data[\"문장\"], data[\"혐오 여부\"],test_size=0.15)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data[\"문장\"])\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(np.asarray(y_train).reshape(-1,1))\n",
    "y_test= encoder.fit_transform(np.asarray(y_test).reshape(-1,1))\n",
    "\n",
    "model = TextRNN(maxlen, max_features, embedding_dims).get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 161495 samples, validate on 28500 samples\n",
      "Epoch 1/100\n",
      "161495/161495 [==============================] - 392s 2ms/step - loss: 0.3001 - accuracy: 0.8514 - val_loss: 0.2812 - val_accuracy: 0.8609\n",
      "Epoch 2/100\n",
      "161495/161495 [==============================] - 418s 3ms/step - loss: 0.2637 - accuracy: 0.8679 - val_loss: 0.2767 - val_accuracy: 0.8646\n",
      "Epoch 3/100\n",
      "161495/161495 [==============================] - 431s 3ms/step - loss: 0.2541 - accuracy: 0.8720 - val_loss: 0.2766 - val_accuracy: 0.8644\n",
      "Epoch 4/100\n",
      "161495/161495 [==============================] - 419s 3ms/step - loss: 0.2456 - accuracy: 0.8755 - val_loss: 0.2824 - val_accuracy: 0.8648\n",
      "Epoch 5/100\n",
      "161495/161495 [==============================] - 405s 3ms/step - loss: 0.2374 - accuracy: 0.8789 - val_loss: 0.2869 - val_accuracy: 0.8630\n",
      "Epoch 6/100\n",
      "161495/161495 [==============================] - 401s 2ms/step - loss: 0.2289 - accuracy: 0.8816 - val_loss: 0.2941 - val_accuracy: 0.8635\n",
      "Epoch 7/100\n",
      "161495/161495 [==============================] - 405s 3ms/step - loss: 0.2210 - accuracy: 0.8850 - val_loss: 0.3076 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c001983188>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hate_speech_topic]",
   "language": "python",
   "name": "conda-env-hate_speech_topic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
